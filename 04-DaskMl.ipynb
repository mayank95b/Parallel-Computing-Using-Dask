{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"30%\"\n",
    "     alt=\"Dask logo\\\">\n",
    "# Machine Learning with Dask\n",
    "Dask-ML provides scalable machine learning in Python using Dask alongside popular machine learning libraries like Scikit-Learn.\n",
    "\n",
    "<img src=\"images/daskML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this offer?\n",
    "The overarching goal of Dask-ML is to enable scalable machine learning.\n",
    "\n",
    "Modern machine learning algorithms employ a wide variety of techniques. Scaling these requires a similarly wide variety of different approaches.\n",
    "#### Generally solutions fall into the following three categories:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallelize Scikit-Learn Directly\n",
    "Scikit-Learn already provides parallel computing on a single machine with Joblib. Dask extends this parallelism to many machines in a cluster. This works well for modest data sizes but large computations, such as random forests, hyper-parameter optimization, and more.\n",
    "\n",
    "#### Reimplement Scalable Algorithms with Dask Array\n",
    "Some machine learning algorithms are easy to write down as Numpy algorithms. In these cases we can replace Numpy arrays with Dask arrays to achieve scalable algorithms easily. This is employed for linear models, pre-processing, and clustering.\n",
    "\n",
    "#### Partner with other distributed libraries\n",
    "Other machine learning libraries like XGBoost and TensorFlow already have distributed solutions that work quite well. Dask-ML makes no attempt to re-implement these systems. Instead, Dask-ML makes it easy to use normal Dask workflows to prepare and set up data, then it deploys XGBoost or Tensorflow alongside Dask, and hands the data over.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn uses joblib for single-machine parallelism. This lets you train most estimators (anything that accepts an n_jobs parameter) using all the cores of your laptop or workstation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, Scikit-Learn can use Dask for parallelism. This lets you train those estimators using all the cores of your cluster without significantly changing your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Scikit-Learn Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use scikit-learn to create a pair of small random arrays, one for the features X, and one for the target y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06377997,  0.67640868,  1.06935647, -0.21758002,  0.46021477,\n",
       "        -0.39916689, -0.07918751,  1.20938491, -0.78531472, -0.17218611,\n",
       "        -1.08535744, -0.99311895,  0.30693511,  0.06405769, -1.0542328 ,\n",
       "        -0.52749607, -0.0741832 , -0.35562842,  1.05721416, -0.90259159],\n",
       "       [ 0.0708476 , -1.69528125,  2.44944917, -0.5304942 , -0.93296221,\n",
       "         2.86520354,  2.43572851, -1.61850016,  1.30071691,  0.34840246,\n",
       "         0.54493439,  0.22532411,  0.60556322, -0.19210097, -0.06802699,\n",
       "         0.9716812 , -1.79204799,  0.01708348, -0.37566904, -0.62323644],\n",
       "       [ 0.94028404, -0.49214582,  0.67795602, -0.22775445,  1.40175261,\n",
       "         1.23165333, -0.77746425,  0.01561602,  1.33171299,  1.08477266,\n",
       "        -0.97805157, -0.05012039,  0.94838552, -0.17342825, -0.47767184,\n",
       "         0.76089649,  1.00115812, -0.06946407,  1.35904607, -1.18958963],\n",
       "       [-0.29951677,  0.75988955,  0.18280267, -1.55023271,  0.33821802,\n",
       "         0.36324148, -2.10052547, -0.4380675 , -0.16639343, -0.34083531,\n",
       "         0.42435643,  1.17872434,  2.8314804 ,  0.14241375, -0.20281911,\n",
       "         2.40571546,  0.31330473,  0.40435568, -0.28754632, -2.8478034 ],\n",
       "       [-2.63062675,  0.23103376,  0.04246253,  0.47885055,  1.54674163,\n",
       "         1.6379556 , -1.53207229, -0.73444479,  0.46585484,  0.4738362 ,\n",
       "         0.98981401, -1.06119392, -0.88887952,  1.23840892, -0.57282854,\n",
       "        -1.27533949,  1.0030065 , -0.47712843,  0.09853558,  0.52780407]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, random_state=0)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll fit a Support Vector Classifier, using grid search to find the best value of the C hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\": [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "              \"kernel\": ['rbf', 'poly', 'sigmoid'],\n",
    "              \"shrinking\": [True, False]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(gamma='auto', random_state=0, probability=True),\n",
    "                           param_grid=param_grid,\n",
    "                           return_train_score=False,\n",
    "                           iid=True,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit that normally, we would call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "  verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0], 'kernel': ['rbf', 'poly', 'sigmoid'], 'shrinking': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit it using the cluster, we just need to use a context manager provided by joblib.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit 48 different models, one for each hyper-parameter combination in param_grid, distributed across the cluster. At this point, we have a regular scikit-learn model, which can be used for prediction, scoring, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_shrinking</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.179921</td>\n",
       "      <td>0.022682</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'rbf', 'shrinking': True}</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187460</td>\n",
       "      <td>0.010090</td>\n",
       "      <td>0.015129</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'rbf', 'shrinking': False}</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.141228</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'poly', 'shrinking': True}</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159508</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'poly', 'shrinking': Fa...</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.220153</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>0.018778</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'sigmoid', 'shrinking':...</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.179921      0.022682         0.013725        0.001215   0.001   \n",
       "1       0.187460      0.010090         0.015129        0.002482   0.001   \n",
       "2       0.141228      0.011814         0.011239        0.001262   0.001   \n",
       "3       0.159508      0.018821         0.010496        0.000650   0.001   \n",
       "4       0.220153      0.020084         0.018778        0.002459   0.001   \n",
       "\n",
       "  param_kernel param_shrinking  \\\n",
       "0          rbf            True   \n",
       "1          rbf           False   \n",
       "2         poly            True   \n",
       "3         poly           False   \n",
       "4      sigmoid            True   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0   {'C': 0.001, 'kernel': 'rbf', 'shrinking': True}           0.502994   \n",
       "1  {'C': 0.001, 'kernel': 'rbf', 'shrinking': False}           0.502994   \n",
       "2  {'C': 0.001, 'kernel': 'poly', 'shrinking': True}           0.502994   \n",
       "3  {'C': 0.001, 'kernel': 'poly', 'shrinking': Fa...           0.502994   \n",
       "4  {'C': 0.001, 'kernel': 'sigmoid', 'shrinking':...           0.502994   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.501502           0.501502            0.502        0.000704   \n",
       "1           0.501502           0.501502            0.502        0.000704   \n",
       "2           0.501502           0.501502            0.502        0.000704   \n",
       "3           0.501502           0.501502            0.502        0.000704   \n",
       "4           0.501502           0.501502            0.502        0.000704   \n",
       "\n",
       "   rank_test_score  \n",
       "0               41  \n",
       "1               41  \n",
       "2               41  \n",
       "3               41  \n",
       "4               41  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(X)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
